import requests
from datetime import date

# ğŸ”§ ë³¸ì¸ Discord Webhook URL ì…ë ¥
DISCORD_WEBHOOK_URL = "https://discord.com/api/webhooks/1425269624215310407/FlmDiO8nrayDSJWioXCaH6zs73_0V_pPBwkfiiIVfqtY2noEGW-PXD8G9vLkdiu1hp2A"


def fetch_papers():
    """Hugging Face Daily Papers RSS JSON ê°€ì ¸ì˜¤ê¸°"""
    url = "https://papers.takara.ai/api/feed"
    resp = requests.get(url)
    resp.raise_for_status()
    return resp.json()


def chunk_message(content, limit=1900):
    """ë””ìŠ¤ì½”ë“œ 2000ì ì œí•œì„ í”¼í•˜ê¸° ìœ„í•œ ë©”ì‹œì§€ ë¶„í• """
    chunks = []
    while len(content) > limit:
        split_idx = content[:limit].rfind("\n\n")
        if split_idx == -1:
            split_idx = limit
        chunks.append(content[:split_idx])
        content = content[split_idx:]
    chunks.append(content)
    return chunks


def summarize_all(papers):
    """ì „ì²´ ë…¼ë¬¸ ìš”ì•½"""
    lines = []
    for idx, p in enumerate(papers, 1):
        title = p.get("title", "ì œëª© ì—†ìŒ")
        authors = ", ".join(p.get("authors", [])) or "ì €ì ì •ë³´ ì—†ìŒ"
        summary = p.get("summary") or p.get("description", "") or "(ìš”ì•½ ì—†ìŒ)"
        link = p.get("url") or p.get("link", "")
        lines.append(f"**{idx}. {title}**\nğŸ‘¥ {authors}\nğŸ“ {summary}\nğŸ”— {link}\n")
    return "\n".join(lines)


def send_to_discord(message):
    """ë©”ì‹œì§€ë¥¼ Discordì— ì „ì†¡ (ìë™ ë¶„í•  í¬í•¨)"""
    chunks = chunk_message(message)
    for chunk in chunks:
        payload = {"content": chunk}
        requests.post(DISCORD_WEBHOOK_URL, json=payload)


def main():
    try:
        papers = fetch_papers()
        today = date.today().strftime("%Y-%m-%d")
        header = f"ğŸ“° **Hugging Face Daily Papers - {today}**\nì´ {len(papers)}í¸\n\n"
        body = summarize_all(papers)
        send_to_discord(header + body)
        print(f"âœ… ì „ì†¡ ì™„ë£Œ ({len(papers)} papers)")
    except Exception as e:
        print("âŒ ì˜¤ë¥˜ ë°œìƒ:", e)


if __name__ == "__main__":
    main()
